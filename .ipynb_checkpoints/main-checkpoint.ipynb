{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d99b7992-cbb5-4f07-a637-8eebddaded61",
   "metadata": {},
   "source": [
    "# 1. Prueba de m√≥dulo \"webscraping\"\n",
    "\n",
    "**scrap_discursos:** Scrap de discursos desde una web paginada con links individuales por discurso.\n",
    "\n",
    "Par√°metros:\n",
    "- base_url (str): URL de inicio.\n",
    "- xpaths (dict): Diccionario con claves: 'link_items', 'boton_siguiente', 'titulo', 'fecha', 'contenido'.\n",
    "- espera (int): Tiempo de espera entre interacciones.\n",
    "- paginas (int): N√∫mero m√°ximo de p√°ginas a recorrer.\n",
    "- articulos_maximos (int): L√≠mite de discursos a scrapear.\n",
    "- headless (bool): Si True, navegador sin interfaz.\n",
    "- verbose (bool): Si True, muestra estado.\n",
    "- output_path (str): Ruta opcional para guardar CSV.\n",
    "- mostrar_tiempo (bool): Si True, muestra tiempo de procesamiento.\n",
    "\n",
    "Retorna:\n",
    "- DataFrame con columnas: 'url', 'titulo', 'fecha', 'contenido', 'codigo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "668e1d8a-32af-4065-968f-d47beed4c337",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\ag_env2\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê P√°gina 1\n",
      "‚ûï 40 nuevos links\n",
      "\n",
      "üîó Total de links √∫nicos obtenidos: 1\n",
      "\n",
      "üìÑ (1/1) Procesando: https://www.casarosada.gob.ar/informacion/discursos/51053-palabras-del-presidente-javier-milei-en-el-141-aniversario-de-la-bolsa-de-comercio-de-rosario\n",
      "üìù Palabras del Presidente Javier Milei en el 141¬∞ aniversario de la Bolsa de Comercio de Rosario (Viernes 22 de agosto de 2025) - 6666 palabras\n",
      "‚úÖ Archivo guardado: C:\\PROYECTOS\\Primer MVP1\\Trabajo final modulo NLP\\data\\A1. discursos.csv\n",
      "‚è± Tiempo total de procesamiento: 63.54 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>titulo</th>\n",
       "      <th>fecha</th>\n",
       "      <th>contenido</th>\n",
       "      <th>codigo</th>\n",
       "      <th>INDEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.casarosada.gob.ar/informacion/disc...</td>\n",
       "      <td>Palabras del Presidente Javier Milei en el 141...</td>\n",
       "      <td>Viernes 22 de agosto de 2025</td>\n",
       "      <td>Palabras del Presidente Javier Milei en el 141...</td>\n",
       "      <td>DISCURSO_001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.casarosada.gob.ar/informacion/disc...   \n",
       "\n",
       "                                              titulo  \\\n",
       "0  Palabras del Presidente Javier Milei en el 141...   \n",
       "\n",
       "                          fecha  \\\n",
       "0  Viernes 22 de agosto de 2025   \n",
       "\n",
       "                                           contenido        codigo  INDEX  \n",
       "0  Palabras del Presidente Javier Milei en el 141...  DISCURSO_001      0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modulos.webscraping import xpaths_casarosada, scrap_discursos\n",
    "import modulos.paths as paths\n",
    "\n",
    "df = scrap_discursos(\n",
    "    base_url=\"https://www.casarosada.gob.ar/informacion/discursos\",\n",
    "    xpaths=xpaths_casarosada,\n",
    "    espera=3,\n",
    "    paginas=5,\n",
    "    articulos_maximos=1,\n",
    "    headless=True,\n",
    "    verbose=True,\n",
    "    output_path=paths.discursos,\n",
    "    mostrar_tiempo=True\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b93f35-d7f9-4e8e-9835-8ed330c7c0b5",
   "metadata": {},
   "source": [
    "# 2. Prueba de m√≥dulo \"preprocesamiento\"\n",
    "\n",
    "## 2.1. Segmentaci√≥n en recortes\n",
    "\n",
    "**generar_recortes:** Convierte una base de discursos en una base de recortes frase a frase.\n",
    "\n",
    "Par√°metros:\n",
    "- df_discursos (DataFrame): Debe tener columnas 'titulo' y 'contenido'.\n",
    "- agregar_codigo (bool): Si True, genera columna 'codigo' con formato DISCURSO_001_FR_001...\n",
    "- prefijo_codigo (str): Prefijo para los c√≥digos asignados.\n",
    "- guardar (bool): Si True, guarda la base generada como CSV.\n",
    "- output_path (str): Ruta del archivo CSV de salida (requerido si guardar=True).\n",
    "- mostrar_tiempo (bool): Si True, muestra tiempo de procesamiento.\n",
    "\n",
    "Retorna:\n",
    "- DataFrame con columnas: 'codigo', 'recorte_id', 'posicion', 'frase'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89b7d00e-3de9-494b-99ed-433a3c785372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo guardado: C:\\PROYECTOS\\Primer MVP1\\Trabajo final modulo NLP\\data\\B1. recortes.csv\n",
      "üßæ La base tiene 276 observaciones (frases).\n",
      "‚è± Tiempo de generar_recortes: 0.01 s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import modulos.paths as paths\n",
    "from modulos.preprocesamiento import generar_recortes\n",
    "\n",
    "# Cargar discursos scrapeados\n",
    "df_discursos = pd.read_csv(paths.discursos, encoding=\"utf-8-sig\")\n",
    "\n",
    "# Generar recortes y guardar\n",
    "df_recortes = generar_recortes(df_discursos, guardar=True, output_path=paths.recortes, mostrar_tiempo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9663b9d2-9bdd-42fb-a744-9b774b92ed6a",
   "metadata": {},
   "source": [
    "## 2.2. Filtrado de discursos por cantidad de frases (m√≠nimo: 24, para series temporales)\n",
    "\n",
    "**filtrar_discursos:** Filtra los c√≥digos que tienen al menos `umbral` frases en `df_recortes`, y opcionalmente guarda los resultados si se indican los paths.\n",
    "\n",
    "Par√°metros:\n",
    "- df: DataFrame original con los textos completos.\n",
    "- df_recortes: DataFrame con las frases (recortes) y la columna 'codigo'.\n",
    "- umbral: Cantidad m√≠nima de frases necesarias para conservar un c√≥digo.\n",
    "- guardar: Si True, guarda los DataFrames filtrados y la lista de c√≥digos eliminados.\n",
    "- path_discursos: Ruta para guardar el CSV de discursos filtrados.\n",
    "- path_recortes: Ruta para guardar el CSV de recortes filtrados.\n",
    "- path_codigos_eliminados: Ruta para guardar el TXT con los c√≥digos eliminados.\n",
    "- mostrar_tiempo (bool): Si True, muestra tiempo de procesamiento.\n",
    "\n",
    "Retorna:\n",
    "- df_filtrado: DataFrame con discursos filtrados.\n",
    "- df_recortes_filtrado: DataFrame de recortes correspondientes a los discursos filtrados.\n",
    "- codigos_eliminados: lista de c√≥digos de discursos eliminados.\n",
    "- codigos_validos : lista de c√≥digos de discursos v√°lidos.\n",
    "- conteo_frases: DataFrame con el conteo total de frases por c√≥digo, antes del filtrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5353fcbf-00b8-4c99-aadf-7d7369639af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de frases por c√≥digo (primeras filas):\n",
      "         codigo  cantidad_frases\n",
      "0  DISCURSO_001              276\n",
      "\n",
      "‚úÖ C√≥digos con al menos 24 frases: 1\n",
      "‚ùå C√≥digos eliminados (menos de 24 frases): 0\n",
      "\n",
      "üìÑ Textos originales tras el filtro: 1\n",
      "üßæ Frases tras el filtro: 276\n",
      "‚úÖ Archivo guardado: C:\\PROYECTOS\\Primer MVP1\\Trabajo final modulo NLP\\data\\A2. discursos_filtrado.csv\n",
      "‚úÖ Archivo guardado: C:\\PROYECTOS\\Primer MVP1\\Trabajo final modulo NLP\\data\\B2. recortes_filtrado.csv\n",
      "\n",
      "üíæ C√≥digos eliminados guardados en: C:\\PROYECTOS\\Primer MVP1\\Trabajo final modulo NLP\\logs\\codigos_eliminados.txt\n",
      "‚è± Tiempo de filtrar_discursos: 0.01 s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import modulos.paths as paths\n",
    "from modulos.preprocesamiento import filtrar_discursos\n",
    "\n",
    "df = pd.read_csv(paths.discursos, encoding=\"utf-8-sig\")\n",
    "df_recortes = pd.read_csv(paths.recortes, encoding=\"utf-8-sig\")\n",
    "\n",
    "df_filtrado, df_recortes_filtrado, codigos_eliminados, codigos_validos, conteo_frases = filtrar_discursos(\n",
    "    df=df,\n",
    "    df_recortes=df_recortes,\n",
    "    umbral=24,\n",
    "    guardar=True,\n",
    "    path_discursos=paths.discursos_filtrado,\n",
    "    path_recortes=paths.recortes_filtrado,\n",
    "    path_codigos_eliminados=paths.codigos_eliminados,\n",
    "    mostrar_tiempo=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0455a48f-415a-4fd3-8a00-4820ededaa59",
   "metadata": {},
   "source": [
    "## 2.3. Limpieza y preprocesamiento\n",
    "\n",
    "**procesar_textos:** Procesa textos en una columna de un DataFrame aplicando limpieza y an√°lisis ling√º√≠stico.\n",
    "\n",
    "Par√°metros:\n",
    "- df (pd.DataFrame): DataFrame original.\n",
    "- columna_texto (str): Nombre de la columna con texto.\n",
    "- texto_limpio (bool): Si se debe incluir columna con texto limpio.\n",
    "- tokens (bool): Si se deben incluir los tokens.\n",
    "- lemmas (bool): Si se deben incluir los lemas.\n",
    "- pos_tags (bool): Si se deben incluir etiquetas POS.\n",
    "- dependencias (bool): Si se deben incluir dependencias sint√°cticas.\n",
    "- entidades (bool): Si se deben incluir entidades nombradas.\n",
    "- sujetos (bool): Si se debe marcar sujeto omitido por frase.\n",
    "- guardar (bool): Si se debe guardar el resultado a CSV.\n",
    "- path_salida (str): Ruta de salida (obligatoria si guardar=True).\n",
    "- mostrar_tiempo (bool): Si True, muestra tiempo de procesamiento.\n",
    "\n",
    "Retorna:\n",
    "- pd.DataFrame: DataFrame con columnas nuevas seg√∫n los flags seleccionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc2cba3e-5325-42a5-8a54-702a1b2f6a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo guardado: C:\\PROYECTOS\\Primer MVP1\\Trabajo final modulo NLP\\data\\A3. discursos_preprocesado.csv\n",
      "‚è± Tiempo de procesar_textos: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import modulos.paths as paths\n",
    "from modulos.preprocesamiento import procesar_textos\n",
    "\n",
    "df_filtrado = pd.read_csv(paths.discursos_filtrado, encoding=\"utf-8-sig\")\n",
    "\n",
    "df_resultado = procesar_textos(\n",
    "    df=df_filtrado,\n",
    "    columna_texto=\"contenido\",\n",
    "    texto_limpio=True,\n",
    "    tokens=False,\n",
    "    lemmas=False,\n",
    "    pos_tags=False,\n",
    "    dependencias=False,\n",
    "    entidades=False,\n",
    "    sujetos=False,\n",
    "    guardar=True,\n",
    "    path_salida=paths.discursos_preprocesado,\n",
    "    mostrar_tiempo=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c14e06d-fa74-4a25-933d-af7ae5b355a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo guardado: C:\\PROYECTOS\\Primer MVP1\\Trabajo final modulo NLP\\data\\B3. recortes_preprocesado.csv\n",
      "‚è± Tiempo de procesar_textos: 3.78 s\n"
     ]
    }
   ],
   "source": [
    "df_recortes_filtrado = pd.read_csv(paths.recortes_filtrado, encoding=\"utf-8-sig\")\n",
    "\n",
    "df_resultado = procesar_textos(\n",
    "    df=df_recortes_filtrado,\n",
    "    columna_texto=\"frase\",\n",
    "    texto_limpio=True,\n",
    "    tokens=True,\n",
    "    lemmas=True,\n",
    "    pos_tags=True,\n",
    "    dependencias=True,\n",
    "    entidades=True,\n",
    "    sujetos=True,\n",
    "    guardar=True,\n",
    "    path_salida=paths.recortes_preprocesado,\n",
    "    mostrar_tiempo=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c5a068-71d7-4d28-8a12-c09a10f841dd",
   "metadata": {},
   "source": [
    "**Nota para optimizaci√≥n:** Ver de que no se dupliquen entidades y dependencias en el archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c3a3ca-7b21-4f07-8805-fca8d9460d90",
   "metadata": {},
   "source": [
    "# 3. Prueba de m√≥dulo \"resumen\"\n",
    "\n",
    "Este m√≥dulo permite generar res√∫menes de discursos extensos utilizando un LLM, a trav√©s de un enfoque por bloques tem√°ticos. La funci√≥n principal aplicada es `resumir_dataframe`.\n",
    "\n",
    "#### L√≥gica del procedimiento\n",
    "\n",
    "- **Segmentaci√≥n sem√°ntica:** el texto se divide en fragmentos seg√∫n cambios tem√°ticos detectados.\n",
    "- **Resumen parcial:** cada fragmento se resume individualmente mediante un LLM.\n",
    "- **Redacci√≥n global:** se produce un resumen final fluido e integrado a partir de los res√∫menes parciales.\n",
    "\n",
    "#### resumir_dataframe\n",
    "\n",
    "Genera res√∫menes utilizando un LLM para cada fila de un DataFrame que contenga la columna `texto_limpio`. Utiliza dos tipos de prompts: uno para fragmentos y otro para la redacci√≥n final del discurso completo.\n",
    "\n",
    "#### Par√°metros\n",
    "\n",
    "- `df` (`pd.DataFrame`): DataFrame con columnas `'codigo'`, `'titulo'`, `'fecha'`, `'texto_limpio'`.\n",
    "- `modelo_llm` (`Callable[[str], str]`): Funci√≥n que toma un prompt (`str`) y devuelve la respuesta generada por el modelo LLM.\n",
    "- `prompt_fragmento` (`str`): Prompt utilizado para resumir cada fragmento segmentado del discurso.\n",
    "- `prompt_discurso` (`str`): Prompt utilizado para redactar el resumen global del discurso a partir de los res√∫menes parciales.\n",
    "- `umbral` (`float`): Umbral de sensibilidad para la segmentaci√≥n tem√°tica. Valores m√°s bajos generan m√°s fragmentos.\n",
    "- `guardar` (`bool`): Si es `True`, guarda el DataFrame resultante en un archivo `.csv`.\n",
    "- `path_salida` (`str`): Ruta del archivo de salida si `guardar=True`.\n",
    "- `mostrar_prompts` (`bool`): Si es `True`, imprime los prompts utilizados durante la ejecuci√≥n (√∫til para debugging).\n",
    "- `mostrar_tiempo` (`bool`): Si `True`, muestra tiempo de procesamiento.\n",
    "- `max_chars_parciales` (`int`, opcional): N√∫mero m√°ximo de caracteres que se permitir√° en cada fragmento antes de enviarlo al LLM. Evita prompts excesivamente largos.\n",
    "- `max_chars_final` (`int`, opcional): N√∫mero m√°ximo de caracteres que se permitir√° en el resumen final antes de enviarlo al LLM. Ayuda a controlar la extensi√≥n del texto generado.\n",
    "\n",
    "#### Retorna\n",
    "\n",
    "- `pd.DataFrame`: DataFrame con una nueva columna `'resumen'` que contiene el resumen generado por LLM para cada discurso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c8a9092-99c2-490e-ab9c-0b8f9ac00dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\ag_env2\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: distiluse-base-multilingual-cased-v1\n",
      "C:\\ProgramData\\anaconda3\\envs\\ag_env2\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ 1 discursos cargados para resumir.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generando res√∫menes con LLM:   0%|                                                                                                                                                                                    | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72a4322ab654a8aade060476d1174fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "Generando res√∫menes con LLM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [01:01<00:00, 61.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üü© Resumen generado con √©xito para c√≥digo: DISCURSO_001\n",
      "Resumen:\n",
      "**Resumen del discurso del Presidente Javier‚ÄØMilei ‚Äì 141.¬∫ aniversario de la Bolsa de Comercio de Rosario**\n",
      "\n",
      "El presidente Javier‚ÄØMilei abri√≥ su intervenci√≥n agradeciendo la invitaci√≥n y expresando orgullo por poder dialogar con el auditorio t√©cnico de la Bolsa de Comercio de Rosario. En un tono claro y directo, se centr√≥ en la volatilidad de la tasa de inter√©s, tema que domina el debate econ√≥mico actual, y explic√≥ que su an√°lisis se desarrollar√° en tres etapas: el problema del dinero y los precios, la cuesti√≥n del tipo de cambio y, finalmente, la tasa de inter√©s. Concluy√≥ se√±alando que la visi√≥n que presenta debe aplicarse a la realidad argentina y a los retos monetarios que enfrenta el pa√≠s en un a√±o electoral.\n",
      "\n",
      "**An√°lisis monetario basado en equilibrio general**\n",
      "\n",
      "Milei fundament√≥ su discurso en un modelo de equilibrio general, partiendo de principios microecon√≥micos y examinando el origen del dinero:\n",
      "\n",
      "1. **Econom√≠a sin dinero**  \n",
      "   - El trueque presenta la doble coincidencia y la indivisibilidad de bienes, provocando p√©rdida de bienestar y la necesidad de un medio com√∫n de intercambio.\n",
      "\n",
      "2. **Evoluci√≥n del dinero**  \n",
      "   - El ganado fue la primera moneda por su portabilidad; posteriormente se emplearon bienes l√≠quidos como trigo y sal. Ejemplos modernos (cigarrillos en c√°rceles) ilustran que el dinero no es un bien deseado per se, sino un medio para facilitar transacciones.\n",
      "\n",
      "3. **Demanda de dinero**  \n",
      "   - La demanda debe reflejar el consumo, no el ingreso ni la tasa de inter√©s. En el modelo de equilibrio general, el ingreso se deriva de precios y cantidades, por lo que incluirlo en la funci√≥n de demanda ser√≠a redundante. La tasa de inter√©s no es el precio del dinero, sino la relaci√≥n entre precios presentes y futuros, vinculada al tiempo.\n",
      "\n",
      "4. **Par√°metros estructurales**  \n",
      "   - El consumo depende de preferencias, tecnolog√≠a, dotaciones y distribuci√≥n de beneficios. Cuando estos par√°metros son fijos, la demanda de dinero se vuelve ‚Äúgran√≠tica‚Äù, explicando por qu√© los modelos cuantitativistas que vinculaban la demanda a una fracci√≥n del ingreso captaban un problema ex√≥geno.\n",
      "\n",
      "5. **Inflaci√≥n y pol√≠tica monetaria**  \n",
      "   - En equilibrio, la oferta real de dinero iguala la demanda, y el nivel de precios es la raz√≥n entre ambas. La inflaci√≥n, por tanto, es siempre un fen√≥meno monetario causado por exceso de oferta de dinero. Milei destac√≥ la reducci√≥n del d√©ficit fiscal y la limpieza del balance del banco central como logros que han puesto la inflaci√≥n en un camino decreciente, pasando de niveles diarios a mensuales.\n",
      "\n",
      "**Contexto electoral**\n",
      "\n",
      "El presidente record√≥ que el futuro electoral se decide en la elecci√≥n del 7‚ÄØde‚ÄØseptiembre. Afirma que el bloque ‚Äúkuka‚Äù representar√° una alternativa clara y que la pol√≠tica monetaria que ha implementado es la clave para garantizar la estabilidad y el crecimiento en el pr√≥ximo mandato.\n",
      "\n",
      "En s√≠ntesis, Milei present√≥ un discurso t√©cnico pero accesible, defendiendo una visi√≥n de equilibrio general que corrige concepciones err√≥neas sobre la demanda de dinero y la tasa de inter√©s, y subray√≥ los logros de su gobierno en la lucha contra la inflaci√≥n y la mejora de la balanza del banco central, todo ello en el marco de un a√±o electoral decisivo.\n",
      "--------------------------------------------------------------------------------\n",
      "‚úÖ Archivo guardado: C:\\PROYECTOS\\Primer MVP1\\Trabajo final modulo NLP\\data\\A4. discursos_resumenes.csv\n",
      "‚è± Tiempo de resumir_dataframe: 61.40 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Prueba con gpt-oss:20b\n",
    "\n",
    "import pandas as pd\n",
    "import modulos.paths as paths\n",
    "import modulos.prompts as prompts\n",
    "from modulos.resumen import resumir_dataframe\n",
    "from modulos.modelo import get_model_ollama_par\n",
    "\n",
    "# Creamos el modelo LLM\n",
    "modelo_llm = get_model_ollama_par(modelo=\"gpt-oss:20b\", temperature=0.0, output_format=\"text\")\n",
    "\n",
    "# Cargamos los discursos preprocesados\n",
    "df_preprocesado = pd.read_csv(paths.discursos_preprocesado, encoding=\"utf-8-sig\")\n",
    "print(f\"üìÑ {len(df_preprocesado)} discursos cargados para resumir.\")\n",
    "\n",
    "# Resumimos los discursos\n",
    "df_con_resumenes = resumir_dataframe(\n",
    "    df=df_preprocesado,\n",
    "    modelo_llm=modelo_llm,\n",
    "    prompt_fragmento=prompts.PROMPT_RESUMIR_FRAGMENTO,\n",
    "    prompt_discurso=prompts.PROMPT_RESUMIR_DISCURSO,\n",
    "    umbral=0.25,\n",
    "    guardar=True,\n",
    "    path_salida=paths.discursos_resumen,\n",
    "    mostrar_prompts=False,\n",
    "    mostrar_tiempo=True,\n",
    "    max_chars_parciales=10000,\n",
    "    max_chars_final=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fe3267-7889-4367-a066-22008b60eb4d",
   "metadata": {},
   "source": [
    "# 4. Prueba de m√≥dulos \"metadatos\" y \"enunciacion\"\n",
    "\n",
    "Estos m√≥dulos permiten la identificaci√≥n autom√°tica de tipo de discurso, enunciador, enunciatarios y lugar de enunciaci√≥n a partir de un conjunto de discursos.\n",
    "La tarea se organiza en dos funciones principales, correspondientes a cada m√≥dulo (metadatos.py y enunciacion.py) que pueden usarse por separado o en conjunto.\n",
    "\n",
    "## 4.1. Procesar tipo de discurso y lugar\n",
    "\n",
    "**procesar_metadatos_llm:** Identifica el tipo de discurso y el lugar de enunciaci√≥n (ciudad, provincia, pa√≠s). Utiliza un modelo de lenguaje (LLM) con prompts personalizados.\n",
    "\n",
    "Par√°metros:\n",
    "- df (pd.DataFrame): DataFrame con columnas 'codigo', 'titulo', 'texto_limpio' y 'resumen'.\n",
    "- modelo_llm (str): Modelo de lenguaje a utilizar (ej. \"gpt-oss:20b\").\n",
    "- diccionario (dict): Diccionario conceptual con categor√≠as y ejemplos, utilizado para orientar la detecci√≥n de tipo de discurso (ej. diccionario_tipos_discurso).\n",
    "- prompt_tipo (str): Prompt base para la detecci√≥n del tipo de discurso. Debe incluir los placeholders \"RESUMEN\", \"FRAGMENTOS\" y \"DICCIONARIO\".\n",
    "- prompt_lugar (str): Prompt base para la detecci√≥n del lugar de enunciaci√≥n. Debe incluir los placeholders \"TITULO\", \"RESUMEN\" y \"FRAGMENTOS\".\n",
    "- guardar (bool, opcional): Si es True, guarda los resultados en un archivo .csv. Por defecto: True.\n",
    "- output_path (str, opcional): Ruta al archivo donde se guardar√° el CSV. Obligatorio si guardar=True.\n",
    "- mostrar_prompts (bool, opcional): Si es True, imprime los prompts construidos antes de enviarlos al modelo (√∫til para debugging). Por defecto: False.\n",
    "- mostrar_tiempo (bool, opcional): Si es True, muestra el tiempo de procesamiento.\n",
    "\n",
    "Retorna:\n",
    "- pd.DataFrame: DataFrame original con columnas adicionales:\n",
    "    - tipo_discurso, tipo_discurso_justificacion\n",
    "    - lugar_ciudad, lugar_provincia, lugar_pais, lugar_justificacion\n",
    "\n",
    "Requiere:\n",
    "- Definici√≥n previa de los paths en el m√≥dulo modulos.paths.\n",
    "- Disponibilidad de los prompts base en el m√≥dulo modulos.prompts.\n",
    "- Diccionario conceptual diccionario_tipos_discurso importado desde modulos.tipos_discurso.\n",
    "\n",
    "## 4.2. Procesar enunciador y enunciatarios\n",
    "\n",
    "**procesar_enunciacion_llm:** Identifica el enunciador y los enunciatarios de un discurso, utilizando un modelo de lenguaje (LLM) con prompts espec√≠ficos.\n",
    "\n",
    "Par√°metros:\n",
    "- df (pd.DataFrame): DataFrame con columnas codigo, titulo, texto_limpio y resumen.\n",
    "- modelo_llm (str): Modelo de lenguaje a utilizar.\n",
    "- diccionario (dict): Diccionario conceptual con categor√≠as y ejemplos, utilizado para orientar la identificaci√≥n de roles enunciativos (ej. diccionario_tipos_discurso).\n",
    "- prompt_enunciacion (str): Prompt base para la identificaci√≥n del enunciador y los enunciatarios. Debe incluir los placeholders \"RESUMEN\", \"FRAGMENTOS\" y \"DICCIONARIO\".\n",
    "- guardar (bool, opcional): Si es True, guarda los resultados en un archivo .csv. Por defecto: True.\n",
    "- output_path (str, opcional): Ruta al archivo donde se guardar√° el CSV. Obligatorio si guardar=True.\n",
    "- mostrar_prompts (bool, opcional): Si es True, imprime los prompts construidos antes de enviarlos al modelo.\n",
    "- mostrar_tiempo (bool, opcional): Si es True, muestra el tiempo de procesamiento.\n",
    "\n",
    "Retorna:\n",
    "- pd.DataFrame: DataFrame original con columnas adicionales:\n",
    "    - enunciador_actor, enunciador_justificacion\n",
    "    - enunciatario_0_actor, enunciatario_0_tipo, enunciatario_0_justificacion\n",
    "    - enunciatario_1_actor, ... (tantos como detecte el modelo).\n",
    "\n",
    "Requiere:\n",
    "- Definici√≥n previa de los paths en el m√≥dulo modulos.paths.\n",
    "- Disponibilidad de los prompts base en el m√≥dulo modulos.prompts.\n",
    "- Diccionario conceptual diccionario_tipos_discurso importado desde modulos.tipos_discurso.\n",
    "\n",
    "### Instanciaci√≥n del modelo LLM\n",
    "Usamos output_format=\"text\" en lugar de format=\"json\" porque:\n",
    "\n",
    "1. En la pr√°ctica, incluso GPT-OSS no siempre devuelve JSON v√°lido.\n",
    "2. StructuredOutputParser de LangChain permite parsear y validar la salida de manera confiable.\n",
    "3. Combinando \"text\" + parser mantenemos robustez frente a peque√±as inconsistencias en la salida del LLM.\n",
    "4. Esto simplifica el pipeline y evita errores de parseo que aparec√≠an con format=\"json\".\n",
    "\n",
    "### Funciones de reprocesamiento\n",
    "En ambos casos, se dise√±aron funciones para reprocesar los errores registrados en la carpeta \"errors\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31be58c1-a417-4ce3-b080-c1452385e8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è± Tiempo de procesar_tipo_lugar_llm: 12.13 s\n"
     ]
    }
   ],
   "source": [
    "# Cargar dataset con res√∫menes\n",
    "import pandas as pd\n",
    "import modulos.paths as paths\n",
    "\n",
    "df_discursos = pd.read_csv(paths.discursos_resumen, encoding=\"utf-8-sig\")\n",
    "\n",
    "# Procesar discursos con el LLM\n",
    "import modulos.prompts as prompts\n",
    "from modulos.metadatos import procesar_metadatos_llm\n",
    "from modulos.tipos_discurso import diccionario_tipos_discurso\n",
    "from modulos.modelo import get_model_ollama_par\n",
    "\n",
    "modelo_llm = get_model_ollama_par(modelo=\"gpt-oss:20b\", temperature=0.0, output_format=\"text\")\n",
    "\n",
    "# Procesar tipo de discurso y lugar\n",
    "df_tipo_lugar = procesar_metadatos_llm(\n",
    "    df=df_discursos,\n",
    "    modelo_llm=modelo_llm,\n",
    "    diccionario=diccionario_tipos_discurso,\n",
    "    prompt_tipo=prompts.PROMPT_TIPO_DISCURSO,\n",
    "    prompt_lugar=prompts.PROMPT_LUGAR,\n",
    "    guardar=True,\n",
    "    output_path=paths.discursos_metadatos,\n",
    "    mostrar_tiempo=True,\n",
    "    mostrar_prompts=False,\n",
    "    path_errores_tipo=paths.errores_metadatos,\n",
    "    path_errores_lugar=paths.errores_metadatos\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cb33144-85b5-497e-8b3a-78e2bb66fd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ No hay errores de metadatos para reprocesar.\n"
     ]
    }
   ],
   "source": [
    "# Reprocesar metadatos en caso de ser necesario\n",
    "\n",
    "import pandas as pd\n",
    "import modulos.paths as paths\n",
    "from modulos.modelo import get_model_ollama_par\n",
    "from modulos.reprocesamiento import reprocesar_errores_metadatos\n",
    "\n",
    "# --- Paths ---\n",
    "path_errores = paths.errores_metadatos\n",
    "path_salida = paths.discursos_metadatos\n",
    "\n",
    "# --- DataFrame original ---\n",
    "df_original = pd.read_csv(paths.discursos_metadatos)\n",
    "\n",
    "# --- Instanciar modelo ---\n",
    "modelo_llm = get_model_ollama_par(modelo=\"gpt-oss:20b\", temperature=0.0, output_format=\"text\")\n",
    "\n",
    "# --- Ejecutar reprocesamiento ---\n",
    "df_corregido = reprocesar_errores_metadatos(\n",
    "    df_original=df_original,\n",
    "    path_errores=path_errores,\n",
    "    modelo_llm=modelo_llm,\n",
    "    intento=1,\n",
    "    mostrar_prompts=False,\n",
    "    path_salida=path_salida\n",
    ")\n",
    "\n",
    "# Nota: Esta funci√≥n debe volver a ser probada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07037594-bf3a-4602-a115-52bf9ca653f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo guardado: C:\\PROYECTOS\\Primer MVP1\\Trabajo final modulo NLP\\data\\A6. discursos_enunciacion.csv\n",
      "‚è± Tiempo de procesar_enunciacion_llm: 15.32 s\n"
     ]
    }
   ],
   "source": [
    "# Cargar dataset con res√∫menes\n",
    "import pandas as pd\n",
    "import modulos.paths as paths\n",
    "\n",
    "df_discursos = pd.read_csv(paths.discursos_metadatos, encoding=\"utf-8-sig\")\n",
    "\n",
    "# Procesar discursos con el LLM\n",
    "import modulos.prompts as prompts\n",
    "from modulos.tipos_discurso import diccionario_tipos_discurso\n",
    "from modulos.enunciacion import procesar_enunciacion_llm\n",
    "from modulos.modelo import get_model_ollama\n",
    "\n",
    "modelo_llm = get_model_ollama_par(modelo=\"gpt-oss:20b\", temperature=0.0, output_format=\"text\")\n",
    "\n",
    "df_resultado = procesar_enunciacion_llm(\n",
    "    df=df_discursos,\n",
    "    modelo_llm=modelo_llm,\n",
    "    diccionario=diccionario_tipos_discurso,\n",
    "    prompt_enunciacion=prompts.PROMPT_ENUNCIACION,\n",
    "    guardar=True,\n",
    "    output_path=paths.discursos_enunc,\n",
    "    mostrar_prompts=False,\n",
    "    mostrar_tiempo=True,\n",
    "    path_errores=paths.errores_enunciacion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89a0d13d-5877-43b6-ad18-3fec7281832c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ No hay errores de enunciaci√≥n para reprocesar.\n"
     ]
    }
   ],
   "source": [
    "# Reprocesar enunciaci√≥n en caso de ser necesario\n",
    "\n",
    "import pandas as pd\n",
    "import modulos.paths as paths\n",
    "from modulos.modelo import get_model_ollama_par\n",
    "from modulos.reprocesamiento import reprocesar_enunciacion\n",
    "\n",
    "# --- Paths ---\n",
    "path_errores = paths.errores_enunciacion\n",
    "path_salida = paths.discursos_enunc\n",
    "\n",
    "# --- DataFrame original ---\n",
    "df_original = pd.read_csv(paths.discursos_enunc)\n",
    "\n",
    "# --- Instanciar modelo ---\n",
    "modelo_llm = get_model_ollama_par(modelo=\"gpt-oss:20b\", temperature=0.0, output_format=\"text\")\n",
    "\n",
    "# --- Ejecutar reprocesamiento ---\n",
    "df_corregido = reprocesar_enunciacion(\n",
    "    df_original=df_original,\n",
    "    path_errores=path_errores,\n",
    "    modelo_llm=modelo_llm,\n",
    "    intento=1,\n",
    "    mostrar_prompts=False,\n",
    "    path_salida=path_salida\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662aa31-b528-41ed-a18f-d12aaa65ac67",
   "metadata": {},
   "source": [
    "# 5. Prueba de m√≥dulo \"identificacion_actores\"\n",
    "\n",
    "## 5.1. Identificaci√≥n de actores\n",
    "\n",
    "**Funci√≥n:** identificar_actores_con_contexto\n",
    "\n",
    "Esta funci√≥n procesa una serie de recortes textuales para identificar actores relevantes mencionados en cada frase. Excluye autom√°ticamente al enunciador y a los enunciatarios previamente detectados.  \n",
    "\n",
    "Para ello, utiliza un modelo de lenguaje (LLM) a trav√©s de la API de Ollama y un **prompt estructurado** que combina:\n",
    "\n",
    "- Informaci√≥n del discurso completo: resumen, fecha, lugar, tipo, enunciador y enunciatarios.  \n",
    "- La frase objetivo y su contexto (frases anteriores y posteriores).  \n",
    "- Heur√≠sticas y ontolog√≠a de actores posibles.\n",
    "\n",
    "### Par√°metros\n",
    "\n",
    "- df_recortes (pd.DataFrame): DataFrame que contiene los recortes textuales a analizar. Debe incluir al menos las columnas:\n",
    "  - 'frase'\n",
    "  - 'recorte_id'\n",
    "  - 'codigo' (identificador del discurso de inscripci√≥n)\n",
    "- df_enunc (pd.DataFrame): DataFrame con los discursos completos y resultados de identificaci√≥n enunciativa (enunciador, enunciatarios, tipo de discurso, lugar, etc.), asociados por la columna 'codigo'.\n",
    "- prompt_actores (str, opcional): Prompt base con placeholders que ser√° completado din√°micamente para cada recorte. Debe incluir:\n",
    "  - {resumen_global}: Resumen del discurso de inscripci√≥n.\n",
    "  - {fecha}: Fecha del discurso.\n",
    "  - {lugar_justificacion}: Lugar del discurso (con justificaci√≥n).\n",
    "  - {tipo_discurso}: Tipo de discurso identificado.\n",
    "  - {enunciador}: Enunciador del discurso.\n",
    "  - {enunciatarios}: Enunciatarios identificados.\n",
    "  - {frase}: Frase objetivo.\n",
    "  - {frases_contexto}: Frases inmediatamente anteriores y posteriores a la frase objetivo.\n",
    "  - {heuristicas}: Lista de reglas de inferencia v√°lidas.\n",
    "  - {ontologia}: Ontolog√≠a de actores posibles (categor√≠as permitidas para clasificaci√≥n).\n",
    "- path_errores (str, opcional): Ruta del archivo donde se guardar√°n los errores o casos que no puedan procesarse correctamente.\n",
    "- output_path (str, opcional): Ruta del archivo donde se guardar√°n los resultados procesados en formato CSV.\n",
    "- modelo_llm (callable, opcional): Funci√≥n o clase del modelo LLM configurado. Debe recibir el prompt como string y devolver una respuesta.\n",
    "- mostrar_prompts (bool, opcional): Si True, imprime el prompt generado para cada fragmento antes de enviarlo al modelo. √ötil para debugging. Por defecto: False.\n",
    "- guardar (bool, opcional): Si True, guarda el DataFrame resultante como CSV en output_path. Por defecto: True.\n",
    "- checkpoint_interval (int, opcional): Frecuencia de guardado parcial en n√∫mero de frases procesadas. Por defecto: 50.\n",
    "- procesador (callable, opcional): Funci√≥n encargada de procesar cada frase individual. Por defecto: procesar_una_frase.\n",
    "\n",
    "### Retorna\n",
    "\n",
    "- pd.DataFrame: Nuevo DataFrame con los actores identificados, con columnas como 'actor', 'tipo', 'modo', 'justificacion', y metadatos de la frase ('frase_idx', 'recorte_id', 'codigo') que permiten vincular cada actor con la frase correspondiente.\n",
    "\n",
    "### Requiere\n",
    "\n",
    "- Definici√≥n previa de los paths relevantes en el m√≥dulo modulos.paths.\n",
    "- Prompt base definido en modulos.prompts.PROMPT_IDENTIFICAR_ACTORES.\n",
    "- Preprocesamiento de enunciadores y enunciatarios mediante la funci√≥n procesar_discursos_llm (u otra que genere df_enunc compatible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e4e8eec-031a-40dd-8521-6c818f24e659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Crear nuevo df de prueba ---\n",
    "df_prueba = df_recortes.head(25)\n",
    "df_prueba.to_csv(\"data/recortes_prueba.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c815dcf-2337-4108-86e8-715068a327a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\ag_env2\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "  0%|                                                                                                                                                                                                                | 0/25 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "  4%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                                                                                                                | 1/25 [00:13<05:27, 13.64s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                                                                                                        | 2/25 [00:30<05:58, 15.60s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                                                                                                | 3/25 [00:41<04:55, 13.45s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                                                                                        | 4/25 [00:53<04:33, 13.05s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                                                                                | 5/25 [01:06<04:16, 12.84s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                                                                        | 6/25 [01:16<03:44, 11.80s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                                                                | 7/25 [01:23<03:07, 10.41s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                                                        | 8/25 [01:41<03:34, 12.60s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                                                | 9/25 [01:50<03:05, 11.59s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                                                                       | 10/25 [02:04<03:05, 12.38s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                                                               | 11/25 [02:14<02:42, 11.58s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                                                       | 12/25 [02:30<02:49, 13.02s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                                               | 13/25 [02:42<02:31, 12.66s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                                       | 14/25 [02:56<02:22, 12.99s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                               | 15/25 [03:04<01:54, 11.49s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                       | 16/25 [03:22<02:02, 13.61s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                               | 17/25 [03:35<01:46, 13.32s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                       | 18/25 [03:53<01:42, 14.64s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                               | 19/25 [04:00<01:13, 12.32s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                       | 20/25 [04:11<00:59, 11.95s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                               | 21/25 [04:24<00:49, 12.34s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 22/25 [04:33<00:33, 11.29s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 23/25 [04:48<00:25, 12.59s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:root:[analizar_generico] Excepci√≥n en Actores idx=23: Tiempo excedido\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 24/25 [05:18<00:17, 17.82s/it]WARNING:root:[analizar_generico] Excepci√≥n en Actores idx=24: Tiempo excedido\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [05:48<00:00, 13.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo guardado: C:\\PROYECTOS\\Primer MVP1\\Trabajo final modulo NLP\\data\\C1. actores_identificados.csv\n",
      "‚è± Tiempo de identificar_actores_con_contexto: 348.87 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import modulos.paths as paths\n",
    "import modulos.prompts as prompts\n",
    "from modulos.identificacion_actores import identificar_actores_con_contexto\n",
    "from modulos.modelo import get_model_ollama_par\n",
    "\n",
    "# --- Cargar data ---\n",
    "df_recortes = pd.read_csv(paths.recortes_preprocesado, encoding=\"utf-8-sig\")\n",
    "df_enunc = pd.read_csv(paths.discursos_enunc, encoding=\"utf-8-sig\")\n",
    "\n",
    "modelo_llm = get_model_ollama_par(modelo=\"gpt-oss:20b\", temperature=0.0, output_format=\"text\")\n",
    "\n",
    "# --- Ejecutar identificaci√≥n de actores ---\n",
    "df_resultado = identificar_actores_con_contexto(\n",
    "    df_recortes=df_prueba, # Reemplazar con df_recortes para an√°lisis completo\n",
    "    df_enunc=df_enunc,\n",
    "    prompt_actores=prompts.PROMPT_IDENTIFICAR_ACTORES,\n",
    "    path_errores=paths.errores_identificacion_actores,\n",
    "    output_path=paths.actores_identificados,\n",
    "    modelo_llm=modelo_llm,\n",
    "    mostrar_prompts=False,\n",
    "    guardar=True,\n",
    "    mostrar_tiempo=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8764eb3-8b04-42b9-a76a-def3c24bb308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor</th>\n",
       "      <th>tipo</th>\n",
       "      <th>modo</th>\n",
       "      <th>justificacion</th>\n",
       "      <th>frase_idx</th>\n",
       "      <th>recorte_id</th>\n",
       "      <th>codigo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bolsa de Comercio de Rosario</td>\n",
       "      <td>institucional</td>\n",
       "      <td>expl√≠cito</td>\n",
       "      <td>explicitly referenced as recipient of saludar ...</td>\n",
       "      <td>0</td>\n",
       "      <td>DISCURSO_001_FR_001</td>\n",
       "      <td>DISCURSO_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bolsa de Comercio de Rosario</td>\n",
       "      <td>institucional</td>\n",
       "      <td>inferido</td>\n",
       "      <td>El invitador no se menciona expl√≠citamente en ...</td>\n",
       "      <td>1</td>\n",
       "      <td>DISCURSO_001_FR_002</td>\n",
       "      <td>DISCURSO_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>economistas</td>\n",
       "      <td>colectivo</td>\n",
       "      <td>expl√≠cito</td>\n",
       "      <td>El sustantivo 'economistas' aparece directamen...</td>\n",
       "      <td>5</td>\n",
       "      <td>DISCURSO_001_FR_006</td>\n",
       "      <td>DISCURSO_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uno</td>\n",
       "      <td>humano_individual</td>\n",
       "      <td>expl√≠cito</td>\n",
       "      <td>Pronombre 'uno' que act√∫a como sujeto de la or...</td>\n",
       "      <td>7</td>\n",
       "      <td>DISCURSO_001_FR_008</td>\n",
       "      <td>DISCURSO_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>un panadero</td>\n",
       "      <td>humano_individual</td>\n",
       "      <td>expl√≠cito</td>\n",
       "      <td>El texto menciona directamente a \"un panadero\"...</td>\n",
       "      <td>10</td>\n",
       "      <td>DISCURSO_001_FR_011</td>\n",
       "      <td>DISCURSO_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>alguien</td>\n",
       "      <td>humano_individual</td>\n",
       "      <td>expl√≠cito</td>\n",
       "      <td>El pronombre indefinido \"alguien\" aparece en l...</td>\n",
       "      <td>11</td>\n",
       "      <td>DISCURSO_001_FR_012</td>\n",
       "      <td>DISCURSO_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>el hombre</td>\n",
       "      <td>humano_individual</td>\n",
       "      <td>expl√≠cito</td>\n",
       "      <td>Mencionado expl√≠citamente como sujeto de la or...</td>\n",
       "      <td>14</td>\n",
       "      <td>DISCURSO_001_FR_015</td>\n",
       "      <td>DISCURSO_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>el hombre</td>\n",
       "      <td>humano_individual</td>\n",
       "      <td>inferido</td>\n",
       "      <td>El verbo 'hizo' es de tercera persona singular...</td>\n",
       "      <td>15</td>\n",
       "      <td>DISCURSO_001_FR_016</td>\n",
       "      <td>DISCURSO_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>el hombre</td>\n",
       "      <td>humano_individual</td>\n",
       "      <td>inferido</td>\n",
       "      <td>Sujeto t√°cito en la frase; el contexto previo ...</td>\n",
       "      <td>16</td>\n",
       "      <td>DISCURSO_001_FR_017</td>\n",
       "      <td>DISCURSO_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>el ser humano</td>\n",
       "      <td>colectivo</td>\n",
       "      <td>expl√≠cito</td>\n",
       "      <td>explicitly mentioned as the subject of the ver...</td>\n",
       "      <td>17</td>\n",
       "      <td>DISCURSO_001_FR_018</td>\n",
       "      <td>DISCURSO_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>el hombre n√≥made</td>\n",
       "      <td>humano_individual</td>\n",
       "      <td>expl√≠cito</td>\n",
       "      <td>explicitly mentioned as subject of the sentence</td>\n",
       "      <td>19</td>\n",
       "      <td>DISCURSO_001_FR_020</td>\n",
       "      <td>DISCURSO_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>el hombre</td>\n",
       "      <td>humano_individual</td>\n",
       "      <td>expl√≠cito</td>\n",
       "      <td>direct mention as subject of the sentence</td>\n",
       "      <td>20</td>\n",
       "      <td>DISCURSO_001_FR_021</td>\n",
       "      <td>DISCURSO_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>el hombre</td>\n",
       "      <td>humano_individual</td>\n",
       "      <td>inferido</td>\n",
       "      <td>El sujeto t√°cito del verbo 'compraba' se infie...</td>\n",
       "      <td>21</td>\n",
       "      <td>DISCURSO_001_FR_022</td>\n",
       "      <td>DISCURSO_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>el hombre</td>\n",
       "      <td>humano_individual</td>\n",
       "      <td>inferido</td>\n",
       "      <td>El contexto previo menciona a 'el hombre' como...</td>\n",
       "      <td>22</td>\n",
       "      <td>DISCURSO_001_FR_023</td>\n",
       "      <td>DISCURSO_001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           actor               tipo       modo  \\\n",
       "0   Bolsa de Comercio de Rosario      institucional  expl√≠cito   \n",
       "1   Bolsa de Comercio de Rosario      institucional   inferido   \n",
       "2                    economistas          colectivo  expl√≠cito   \n",
       "3                            uno  humano_individual  expl√≠cito   \n",
       "4                    un panadero  humano_individual  expl√≠cito   \n",
       "5                        alguien  humano_individual  expl√≠cito   \n",
       "6                      el hombre  humano_individual  expl√≠cito   \n",
       "7                      el hombre  humano_individual   inferido   \n",
       "8                      el hombre  humano_individual   inferido   \n",
       "9                  el ser humano          colectivo  expl√≠cito   \n",
       "10              el hombre n√≥made  humano_individual  expl√≠cito   \n",
       "11                     el hombre  humano_individual  expl√≠cito   \n",
       "12                     el hombre  humano_individual   inferido   \n",
       "13                     el hombre  humano_individual   inferido   \n",
       "\n",
       "                                        justificacion  frase_idx  \\\n",
       "0   explicitly referenced as recipient of saludar ...          0   \n",
       "1   El invitador no se menciona expl√≠citamente en ...          1   \n",
       "2   El sustantivo 'economistas' aparece directamen...          5   \n",
       "3   Pronombre 'uno' que act√∫a como sujeto de la or...          7   \n",
       "4   El texto menciona directamente a \"un panadero\"...         10   \n",
       "5   El pronombre indefinido \"alguien\" aparece en l...         11   \n",
       "6   Mencionado expl√≠citamente como sujeto de la or...         14   \n",
       "7   El verbo 'hizo' es de tercera persona singular...         15   \n",
       "8   Sujeto t√°cito en la frase; el contexto previo ...         16   \n",
       "9   explicitly mentioned as the subject of the ver...         17   \n",
       "10    explicitly mentioned as subject of the sentence         19   \n",
       "11          direct mention as subject of the sentence         20   \n",
       "12  El sujeto t√°cito del verbo 'compraba' se infie...         21   \n",
       "13  El contexto previo menciona a 'el hombre' como...         22   \n",
       "\n",
       "             recorte_id        codigo  \n",
       "0   DISCURSO_001_FR_001  DISCURSO_001  \n",
       "1   DISCURSO_001_FR_002  DISCURSO_001  \n",
       "2   DISCURSO_001_FR_006  DISCURSO_001  \n",
       "3   DISCURSO_001_FR_008  DISCURSO_001  \n",
       "4   DISCURSO_001_FR_011  DISCURSO_001  \n",
       "5   DISCURSO_001_FR_012  DISCURSO_001  \n",
       "6   DISCURSO_001_FR_015  DISCURSO_001  \n",
       "7   DISCURSO_001_FR_016  DISCURSO_001  \n",
       "8   DISCURSO_001_FR_017  DISCURSO_001  \n",
       "9   DISCURSO_001_FR_018  DISCURSO_001  \n",
       "10  DISCURSO_001_FR_020  DISCURSO_001  \n",
       "11  DISCURSO_001_FR_021  DISCURSO_001  \n",
       "12  DISCURSO_001_FR_022  DISCURSO_001  \n",
       "13  DISCURSO_001_FR_023  DISCURSO_001  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actores = pd.read_csv(paths.actores_identificados, encoding=\"utf-8-sig\")\n",
    "\n",
    "df_actores.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756fcc2c-0a48-4d96-b915-007e4cb913dc",
   "metadata": {},
   "source": [
    "## 5.2. Funciones de postprocesamiento de actores\n",
    "\n",
    "### 5.2.1. Funci√≥n para propagar actores por pronombres\n",
    "\n",
    "Dado que no siempre el LLM lo realiza adecuadamente, esta funci√≥n secundaria permite **propagar actores referidos por pronombres entre frases dentro de un mismo discurso**, asegurando mayor granularidad en la identificaci√≥n de actores cuando las frases son cortas o abstractas.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import modulos.paths as paths\n",
    "from modulos.postprocesamiento_actores import propagar_actores_por_pronombres\n",
    "\n",
    "# Cargar CSV con actores identificados previamente\n",
    "df_actores = pd.read_csv(paths.actores_identificados)\n",
    "\n",
    "# Aplicar propagaci√≥n de pronombres\n",
    "df_actores_con_pronombres = propagar_actores_por_pronombres(df_actores)\n",
    "\n",
    "# Nota: esta operaci√≥n no guarda el resultado autom√°ticamente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88521ac3-ddf5-4441-825d-03bb57d82881",
   "metadata": {},
   "source": [
    "### 5.2.2. Funci√≥n para reprocesar errores de identificaci√≥n de actores\n",
    "\n",
    "En caso de que algunas frases no hayan sido procesadas correctamente por el LLM, esta funci√≥n permite **reprocesar los errores registrados**, recuperando resultados potencialmente perdidos y guardando aquellos errores que persistan tras un nuevo intento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66bf8a20-451c-45a4-af03-0267229185a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Reprocesando 2 errores de identificaci√≥n...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Resultado vac√≠o/inv√°lido INDEX=23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Resultado vac√≠o/inv√°lido INDEX=24\n",
      "‚úÖ Guardados 2 errores persistentes en C:\\PROYECTOS\\Primer MVP1\\Trabajo final modulo NLP\\errors\\errores_actores_persistentes.jsonl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import modulos.paths as paths\n",
    "import modulos.prompts as prompts\n",
    "from modulos.modelo import get_model_ollama_par\n",
    "from modulos.reprocesamiento import reprocesar_errores_identificacion\n",
    "\n",
    "# --- Cargar data ---\n",
    "df_recortes = pd.read_csv(paths.recortes_preprocesado, encoding=\"utf-8-sig\")\n",
    "df_enunc = pd.read_csv(paths.discursos_enunc, encoding=\"utf-8-sig\")\n",
    "\n",
    "# --- Crear nuevo df de prueba ---\n",
    "df_prueba = df_recortes.head(25)\n",
    "df_prueba.to_csv(\"data/recortes_prueba.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Instanciar modelo\n",
    "modelo_llm = get_model_ollama_par(modelo=\"gpt-oss:20b\", temperature=0.0, output_format=\"text\")\n",
    "\n",
    "# Reprocesar errores con el mismo prompt utilizado originalmente\n",
    "reprocesar_errores_identificacion(\n",
    "    df_recortes=df_recortes,\n",
    "    df_enunc=df_enunc,\n",
    "    path_errores=paths.errores_identificacion_actores,\n",
    "    path_salida=paths.actores_identificados,\n",
    "    prompt_actores=prompts.PROMPT_IDENTIFICAR_ACTORES,\n",
    "    intento=1,\n",
    "    evitar_duplicados=True,\n",
    "    modelo_llm=modelo_llm,\n",
    "    mostrar_prompts=False\n",
    ")\n",
    "\n",
    "# Nota: la funci√≥n guarda autom√°ticamente los resultados recuperados y los errores persistentes en nuevos archivos\n",
    "# Nota: Los errores de identificaci√≥n pueden corresponder a frases donde el LLM no encuentra actores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160ce61a-e177-47e8-9a41-3cbf7b3751bd",
   "metadata": {},
   "source": [
    "### 5.2.3. Funci√≥n para validar actores seg√∫n ontolog√≠a\n",
    "\n",
    "Esta funci√≥n permite **validar actores previamente identificados usando un LLM**, comparando cada actor con los tipos definidos en la ontolog√≠a. Los actores que cumplen los criterios se guardan en un archivo de v√°lidos, mientras que los que no cumplen o generan respuestas ambiguas se guardan en un archivo de excluidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fad4ae2c-b15e-40a2-b380-b8ab8498b49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando recortes:   0%|                                                                                                                                                                                           | 0/14 [00:00<?, ?it/s]\n",
      "Validando actores recorte DISCURSO_001_FR_001:   0%|                                                                                                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[AINFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\n",
      "Validando actores recorte DISCURSO_001_FR_001: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.22s/it]\u001b[A\n",
      "Procesando recortes:   7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                                                                                                                      | 1/14 [00:03<00:41,  3.22s/it]\u001b[A\n",
      "Validando actores recorte DISCURSO_001_FR_002:   0%|                                                                                                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[AINFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\n",
      "Validando actores recorte DISCURSO_001_FR_002: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.69s/it]\u001b[A\n",
      "Procesando recortes:  14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                                                                                                         | 2/14 [00:05<00:34,  2.91s/it]\u001b[A\n",
      "Validando actores recorte DISCURSO_001_FR_006:   0%|                                                                                                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[AINFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\n",
      "Validando actores recorte DISCURSO_001_FR_006: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.82s/it]\u001b[A\n",
      "Procesando recortes:  21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                                                                                            | 3/14 [00:07<00:26,  2.41s/it]\u001b[A\n",
      "Validando actores recorte DISCURSO_001_FR_008:   0%|                                                                                                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[AINFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\n",
      "Validando actores recorte DISCURSO_001_FR_008: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.60s/it]\u001b[A\n",
      "Procesando recortes:  29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                                               | 4/14 [00:14<00:40,  4.07s/it]\u001b[A\n",
      "Validando actores recorte DISCURSO_001_FR_011:   0%|                                                                                                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[AINFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\n",
      "Validando actores recorte DISCURSO_001_FR_011: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.94s/it]\u001b[A\n",
      "Procesando recortes:  36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                                                                   | 5/14 [00:16<00:29,  3.30s/it]\u001b[A\n",
      "Validando actores recorte DISCURSO_001_FR_012:   0%|                                                                                                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[AINFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\n",
      "Validando actores recorte DISCURSO_001_FR_012: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.14s/it]\u001b[A\n",
      "Procesando recortes:  43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                                                      | 6/14 [00:19<00:25,  3.25s/it]\u001b[A\n",
      "Validando actores recorte DISCURSO_001_FR_015:   0%|                                                                                                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[AINFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\n",
      "Validando actores recorte DISCURSO_001_FR_015: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.57s/it]\u001b[A\n",
      "Procesando recortes:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                                         | 7/14 [00:24<00:28,  4.01s/it]\u001b[A\n",
      "Validando actores recorte DISCURSO_001_FR_016:   0%|                                                                                                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[AINFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\n",
      "Validando actores recorte DISCURSO_001_FR_016: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n",
      "Procesando recortes:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                            | 8/14 [00:26<00:20,  3.36s/it]\u001b[A\n",
      "Validando actores recorte DISCURSO_001_FR_017:   0%|                                                                                                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[AINFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\n",
      "Validando actores recorte DISCURSO_001_FR_017: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.59s/it]\u001b[A\n",
      "Procesando recortes:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                | 9/14 [00:32<00:20,  4.06s/it]\u001b[A\n",
      "Validando actores recorte DISCURSO_001_FR_018:   0%|                                                                                                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[AINFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\n",
      "Validando actores recorte DISCURSO_001_FR_018: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.21s/it]\u001b[A\n",
      "Procesando recortes:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                  | 10/14 [00:38<00:18,  4.72s/it]\u001b[A\n",
      "Validando actores recorte DISCURSO_001_FR_020:   0%|                                                                                                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[AINFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\n",
      "Validando actores recorte DISCURSO_001_FR_020: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.82s/it]\u001b[A\n",
      "Procesando recortes:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                      | 11/14 [00:40<00:11,  3.84s/it]\u001b[A\n",
      "Validando actores recorte DISCURSO_001_FR_021:   0%|                                                                                                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[AINFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\n",
      "Validando actores recorte DISCURSO_001_FR_021: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.16s/it]\u001b[A\n",
      "Procesando recortes:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 12/14 [00:43<00:07,  3.63s/it]\u001b[A\n",
      "Validando actores recorte DISCURSO_001_FR_022:   0%|                                                                                                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[AINFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\n",
      "Validando actores recorte DISCURSO_001_FR_022: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.50s/it]\u001b[A\n",
      "Procesando recortes:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 13/14 [00:46<00:03,  3.29s/it]\u001b[A\n",
      "Validando actores recorte DISCURSO_001_FR_023:   0%|                                                                                                                                                                  | 0/1 [00:00<?, ?it/s]\u001b[AINFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\n",
      "Validando actores recorte DISCURSO_001_FR_023: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.33s/it]\u001b[A\n",
      "Procesando recortes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:50<00:00,  3.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Guardados 14 actores validados en 'C:\\PROYECTOS\\Primer MVP1\\Trabajo final modulo NLP\\data\\C2. actores_validos.csv'\n",
      "‚úÖ No hubo actores excluidos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import modulos.paths as paths\n",
    "from modulos.modelo import get_model_ollama_par\n",
    "from modulos.postprocesamiento_actores import validacion_actores\n",
    "\n",
    "path_df_actores = paths.actores_identificados\n",
    "path_df_recortes = pd.read_csv(\"data/recortes_prueba.csv\", encoding=\"utf-8-sig\") # Para an√°lisis completo, reemplazar el path con paths.recortes_preprocesado)\n",
    "path_salida_validos = paths.actores_validos\n",
    "path_salida_excluidos = paths.actores_excluidos\n",
    "\n",
    "# Instanciar modelo\n",
    "modelo_llm = get_model_ollama_par(modelo=\"gpt-oss:20b\", temperature=0.0, output_format=\"text\")\n",
    "\n",
    "validacion_actores(\n",
    "    path_df_actores=path_df_actores,\n",
    "    path_df_recortes=path_df_recortes,\n",
    "    path_salida_validos=path_salida_validos,\n",
    "    path_salida_excluidos=path_salida_excluidos,\n",
    "    modelo_llm=modelo_llm,\n",
    "    mostrar_prompts=False\n",
    ")\n",
    "\n",
    "# Nota: la funci√≥n recorre cada actor por recorte, llama al LLM con el prompt definido en `PROMPT_VALIDAR_ACTORES`,\n",
    "# clasifica la respuesta como \"V√°lido\" o \"Excluido\" y guarda autom√°ticamente los resultados en los archivos indicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845303c8-3b29-49a0-bf37-71a6c0a891e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e608fa88-c18c-4491-b7e0-2c868406872c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
